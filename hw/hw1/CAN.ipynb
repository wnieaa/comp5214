{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of testing samples: 10000\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = th.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = th.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of testing samples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CAN(nn.Module):\n",
    "    def __init__(self, num_channels=32):\n",
    "        super(CAN, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(1, num_channels, 3, padding=1)\n",
    "        self.fc2 = nn.Conv2d(num_channels, num_channels, 3, dilation=2, padding=2)\n",
    "        self.fc3 = nn.Conv2d(num_channels, num_channels, 3, dilation=4, padding=4)\n",
    "        self.fc4 = nn.Conv2d(num_channels, num_channels, 3, dilation=8, padding=8)\n",
    "        self.fc5 = nn.Conv2d(num_channels, 10, 3, dilation=1, padding=1)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(28)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = F.leaky_relu(self.fc4(x))\n",
    "        x = F.leaky_relu(self.fc5(x))\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(-1, 10)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, epochs, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 300 == 299:\n",
    "                print(f\"Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 300:.6f}\")\n",
    "            running_loss = 0.0\n",
    "        print(\"Epoch: {} Loss: {}\".format(epoch, running_loss))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = th.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %0.2f %%' % (100 * correct / total))\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 300, Loss: 0.007672\n",
      "Epoch: 1, Batch: 600, Loss: 0.006923\n",
      "Epoch: 1, Batch: 900, Loss: 0.004998\n",
      "Epoch: 0 Loss: 0.0\n",
      "Epoch: 2, Batch: 300, Loss: 0.001584\n",
      "Epoch: 2, Batch: 600, Loss: 0.000567\n",
      "Epoch: 2, Batch: 900, Loss: 0.000344\n",
      "Epoch: 1 Loss: 0.0\n",
      "Epoch: 3, Batch: 300, Loss: 0.000562\n",
      "Epoch: 3, Batch: 600, Loss: 0.000467\n",
      "Epoch: 3, Batch: 900, Loss: 0.000355\n",
      "Epoch: 2 Loss: 0.0\n",
      "Epoch: 4, Batch: 300, Loss: 0.000670\n",
      "Epoch: 4, Batch: 600, Loss: 0.000401\n",
      "Epoch: 4, Batch: 900, Loss: 0.000799\n",
      "Epoch: 3 Loss: 0.0\n",
      "Epoch: 5, Batch: 300, Loss: 0.000445\n",
      "Epoch: 5, Batch: 600, Loss: 0.000194\n",
      "Epoch: 5, Batch: 900, Loss: 0.000420\n",
      "Epoch: 4 Loss: 0.0\n",
      "Epoch: 6, Batch: 300, Loss: 0.000171\n",
      "Epoch: 6, Batch: 600, Loss: 0.000137\n",
      "Epoch: 6, Batch: 900, Loss: 0.000097\n",
      "Epoch: 5 Loss: 0.0\n",
      "Epoch: 7, Batch: 300, Loss: 0.000112\n",
      "Epoch: 7, Batch: 600, Loss: 0.000275\n",
      "Epoch: 7, Batch: 900, Loss: 0.000448\n",
      "Epoch: 6 Loss: 0.0\n",
      "Epoch: 8, Batch: 300, Loss: 0.000196\n",
      "Epoch: 8, Batch: 600, Loss: 0.000191\n",
      "Epoch: 8, Batch: 900, Loss: 0.000270\n",
      "Epoch: 7 Loss: 0.0\n",
      "Epoch: 9, Batch: 300, Loss: 0.000033\n",
      "Epoch: 9, Batch: 600, Loss: 0.000451\n",
      "Epoch: 9, Batch: 900, Loss: 0.000047\n",
      "Epoch: 8 Loss: 0.0\n",
      "Epoch: 10, Batch: 300, Loss: 0.000079\n",
      "Epoch: 10, Batch: 600, Loss: 0.000400\n",
      "Epoch: 10, Batch: 900, Loss: 0.000231\n",
      "Epoch: 9 Loss: 0.0\n",
      "Epoch: 11, Batch: 300, Loss: 0.000183\n",
      "Epoch: 11, Batch: 600, Loss: 0.000082\n",
      "Epoch: 11, Batch: 900, Loss: 0.000457\n",
      "Epoch: 10 Loss: 0.0\n",
      "Epoch: 12, Batch: 300, Loss: 0.000048\n",
      "Epoch: 12, Batch: 600, Loss: 0.000024\n",
      "Epoch: 12, Batch: 900, Loss: 0.000054\n",
      "Epoch: 11 Loss: 0.0\n",
      "Epoch: 13, Batch: 300, Loss: 0.000005\n",
      "Epoch: 13, Batch: 600, Loss: 0.000220\n",
      "Epoch: 13, Batch: 900, Loss: 0.000268\n",
      "Epoch: 12 Loss: 0.0\n",
      "Epoch: 14, Batch: 300, Loss: 0.000015\n",
      "Epoch: 14, Batch: 600, Loss: 0.000172\n",
      "Epoch: 14, Batch: 900, Loss: 0.000277\n",
      "Epoch: 13 Loss: 0.0\n",
      "Epoch: 15, Batch: 300, Loss: 0.000142\n",
      "Epoch: 15, Batch: 600, Loss: 0.000101\n",
      "Epoch: 15, Batch: 900, Loss: 0.000058\n",
      "Epoch: 14 Loss: 0.0\n",
      "Epoch: 16, Batch: 300, Loss: 0.000029\n",
      "Epoch: 16, Batch: 600, Loss: 0.000098\n",
      "Epoch: 16, Batch: 900, Loss: 0.000185\n",
      "Epoch: 15 Loss: 0.0\n",
      "Epoch: 17, Batch: 300, Loss: 0.000088\n",
      "Epoch: 17, Batch: 600, Loss: 0.000034\n",
      "Epoch: 17, Batch: 900, Loss: 0.000031\n",
      "Epoch: 16 Loss: 0.0\n",
      "Epoch: 18, Batch: 300, Loss: 0.000162\n",
      "Epoch: 18, Batch: 600, Loss: 0.000117\n",
      "Epoch: 18, Batch: 900, Loss: 0.000029\n",
      "Epoch: 17 Loss: 0.0\n",
      "Epoch: 19, Batch: 300, Loss: 0.000178\n",
      "Epoch: 19, Batch: 600, Loss: 0.000011\n",
      "Epoch: 19, Batch: 900, Loss: 0.000334\n",
      "Epoch: 18 Loss: 0.0\n",
      "Epoch: 20, Batch: 300, Loss: 0.000205\n",
      "Epoch: 20, Batch: 600, Loss: 0.000024\n",
      "Epoch: 20, Batch: 900, Loss: 0.000013\n",
      "Epoch: 19 Loss: 0.0\n",
      "Accuracy of the network on the 10000 test images: 98.87 %\n",
      "Epoch: 1, Batch: 300, Loss: 0.007646\n",
      "Epoch: 1, Batch: 600, Loss: 0.007256\n",
      "Epoch: 1, Batch: 900, Loss: 0.004126\n",
      "Epoch: 0 Loss: 0.0\n",
      "Epoch: 2, Batch: 300, Loss: 0.000953\n",
      "Epoch: 2, Batch: 600, Loss: 0.001037\n",
      "Epoch: 2, Batch: 900, Loss: 0.000876\n",
      "Epoch: 1 Loss: 0.0\n",
      "Epoch: 3, Batch: 300, Loss: 0.000238\n",
      "Epoch: 3, Batch: 600, Loss: 0.000730\n",
      "Epoch: 3, Batch: 900, Loss: 0.000790\n",
      "Epoch: 2 Loss: 0.0\n",
      "Epoch: 4, Batch: 300, Loss: 0.000271\n",
      "Epoch: 4, Batch: 600, Loss: 0.000204\n",
      "Epoch: 4, Batch: 900, Loss: 0.000643\n",
      "Epoch: 3 Loss: 0.0\n",
      "Epoch: 5, Batch: 300, Loss: 0.000267\n",
      "Epoch: 5, Batch: 600, Loss: 0.000196\n",
      "Epoch: 5, Batch: 900, Loss: 0.000145\n",
      "Epoch: 4 Loss: 0.0\n",
      "Epoch: 6, Batch: 300, Loss: 0.000211\n",
      "Epoch: 6, Batch: 600, Loss: 0.000272\n",
      "Epoch: 6, Batch: 900, Loss: 0.000480\n",
      "Epoch: 5 Loss: 0.0\n",
      "Epoch: 7, Batch: 300, Loss: 0.000080\n",
      "Epoch: 7, Batch: 600, Loss: 0.000124\n",
      "Epoch: 7, Batch: 900, Loss: 0.000147\n",
      "Epoch: 6 Loss: 0.0\n",
      "Epoch: 8, Batch: 300, Loss: 0.000157\n",
      "Epoch: 8, Batch: 600, Loss: 0.000273\n",
      "Epoch: 8, Batch: 900, Loss: 0.000324\n",
      "Epoch: 7 Loss: 0.0\n",
      "Epoch: 9, Batch: 300, Loss: 0.000843\n",
      "Epoch: 9, Batch: 600, Loss: 0.000096\n",
      "Epoch: 9, Batch: 900, Loss: 0.000015\n",
      "Epoch: 8 Loss: 0.0\n",
      "Epoch: 10, Batch: 300, Loss: 0.000080\n",
      "Epoch: 10, Batch: 600, Loss: 0.000166\n",
      "Epoch: 10, Batch: 900, Loss: 0.000039\n",
      "Epoch: 9 Loss: 0.0\n",
      "Epoch: 11, Batch: 300, Loss: 0.000177\n",
      "Epoch: 11, Batch: 600, Loss: 0.000052\n",
      "Epoch: 11, Batch: 900, Loss: 0.000108\n",
      "Epoch: 10 Loss: 0.0\n",
      "Epoch: 12, Batch: 300, Loss: 0.000126\n",
      "Epoch: 12, Batch: 600, Loss: 0.000209\n",
      "Epoch: 12, Batch: 900, Loss: 0.000008\n",
      "Epoch: 11 Loss: 0.0\n",
      "Epoch: 13, Batch: 300, Loss: 0.000288\n",
      "Epoch: 13, Batch: 600, Loss: 0.000125\n",
      "Epoch: 13, Batch: 900, Loss: 0.000170\n",
      "Epoch: 12 Loss: 0.0\n",
      "Epoch: 14, Batch: 300, Loss: 0.000004\n",
      "Epoch: 14, Batch: 600, Loss: 0.000043\n",
      "Epoch: 14, Batch: 900, Loss: 0.000085\n",
      "Epoch: 13 Loss: 0.0\n",
      "Epoch: 15, Batch: 300, Loss: 0.000018\n",
      "Epoch: 15, Batch: 600, Loss: 0.000061\n",
      "Epoch: 15, Batch: 900, Loss: 0.000110\n",
      "Epoch: 14 Loss: 0.0\n",
      "Epoch: 16, Batch: 300, Loss: 0.000080\n",
      "Epoch: 16, Batch: 600, Loss: 0.000008\n",
      "Epoch: 16, Batch: 900, Loss: 0.000251\n",
      "Epoch: 15 Loss: 0.0\n",
      "Epoch: 17, Batch: 300, Loss: 0.000093\n",
      "Epoch: 17, Batch: 600, Loss: 0.000949\n",
      "Epoch: 17, Batch: 900, Loss: 0.000031\n",
      "Epoch: 16 Loss: 0.0\n",
      "Epoch: 18, Batch: 300, Loss: 0.000146\n",
      "Epoch: 18, Batch: 600, Loss: 0.000321\n",
      "Epoch: 18, Batch: 900, Loss: 0.000220\n",
      "Epoch: 17 Loss: 0.0\n",
      "Epoch: 19, Batch: 300, Loss: 0.000038\n",
      "Epoch: 19, Batch: 600, Loss: 0.000111\n",
      "Epoch: 19, Batch: 900, Loss: 0.000246\n",
      "Epoch: 18 Loss: 0.0\n",
      "Epoch: 20, Batch: 300, Loss: 0.000059\n",
      "Epoch: 20, Batch: 600, Loss: 0.000006\n",
      "Epoch: 20, Batch: 900, Loss: 0.000123\n",
      "Epoch: 19 Loss: 0.0\n",
      "Accuracy of the network on the 10000 test images: 99.31 %\n",
      "Epoch: 1, Batch: 300, Loss: 0.007314\n",
      "Epoch: 1, Batch: 600, Loss: 0.003460\n",
      "Epoch: 1, Batch: 900, Loss: 0.001039\n",
      "Epoch: 0 Loss: 0.0\n",
      "Epoch: 2, Batch: 300, Loss: 0.000799\n",
      "Epoch: 2, Batch: 600, Loss: 0.000369\n",
      "Epoch: 2, Batch: 900, Loss: 0.000265\n",
      "Epoch: 1 Loss: 0.0\n",
      "Epoch: 3, Batch: 300, Loss: 0.000399\n",
      "Epoch: 3, Batch: 600, Loss: 0.000394\n",
      "Epoch: 3, Batch: 900, Loss: 0.000349\n",
      "Epoch: 2 Loss: 0.0\n",
      "Epoch: 4, Batch: 300, Loss: 0.000270\n",
      "Epoch: 4, Batch: 600, Loss: 0.000529\n",
      "Epoch: 4, Batch: 900, Loss: 0.000022\n",
      "Epoch: 3 Loss: 0.0\n",
      "Epoch: 5, Batch: 300, Loss: 0.000064\n",
      "Epoch: 5, Batch: 600, Loss: 0.000106\n",
      "Epoch: 5, Batch: 900, Loss: 0.000196\n",
      "Epoch: 4 Loss: 0.0\n",
      "Epoch: 6, Batch: 300, Loss: 0.000205\n",
      "Epoch: 6, Batch: 600, Loss: 0.000264\n",
      "Epoch: 6, Batch: 900, Loss: 0.000123\n",
      "Epoch: 5 Loss: 0.0\n",
      "Epoch: 7, Batch: 300, Loss: 0.000069\n",
      "Epoch: 7, Batch: 600, Loss: 0.000184\n",
      "Epoch: 7, Batch: 900, Loss: 0.000035\n",
      "Epoch: 6 Loss: 0.0\n",
      "Epoch: 8, Batch: 300, Loss: 0.000045\n",
      "Epoch: 8, Batch: 600, Loss: 0.000121\n",
      "Epoch: 8, Batch: 900, Loss: 0.000364\n",
      "Epoch: 7 Loss: 0.0\n",
      "Epoch: 9, Batch: 300, Loss: 0.000079\n",
      "Epoch: 9, Batch: 600, Loss: 0.000032\n",
      "Epoch: 9, Batch: 900, Loss: 0.000261\n",
      "Epoch: 8 Loss: 0.0\n",
      "Epoch: 10, Batch: 300, Loss: 0.000061\n",
      "Epoch: 10, Batch: 600, Loss: 0.000243\n",
      "Epoch: 10, Batch: 900, Loss: 0.000059\n",
      "Epoch: 9 Loss: 0.0\n",
      "Epoch: 11, Batch: 300, Loss: 0.000007\n",
      "Epoch: 11, Batch: 600, Loss: 0.000129\n",
      "Epoch: 11, Batch: 900, Loss: 0.000161\n",
      "Epoch: 10 Loss: 0.0\n",
      "Epoch: 12, Batch: 300, Loss: 0.000024\n",
      "Epoch: 12, Batch: 600, Loss: 0.000023\n",
      "Epoch: 12, Batch: 900, Loss: 0.000136\n",
      "Epoch: 11 Loss: 0.0\n",
      "Epoch: 13, Batch: 300, Loss: 0.000097\n",
      "Epoch: 13, Batch: 600, Loss: 0.000526\n",
      "Epoch: 13, Batch: 900, Loss: 0.000007\n",
      "Epoch: 12 Loss: 0.0\n",
      "Epoch: 14, Batch: 300, Loss: 0.000530\n",
      "Epoch: 14, Batch: 600, Loss: 0.000065\n",
      "Epoch: 14, Batch: 900, Loss: 0.000335\n",
      "Epoch: 13 Loss: 0.0\n",
      "Epoch: 15, Batch: 300, Loss: 0.000028\n",
      "Epoch: 15, Batch: 600, Loss: 0.000591\n",
      "Epoch: 15, Batch: 900, Loss: 0.000015\n",
      "Epoch: 14 Loss: 0.0\n",
      "Epoch: 16, Batch: 300, Loss: 0.000077\n",
      "Epoch: 16, Batch: 600, Loss: 0.000089\n",
      "Epoch: 16, Batch: 900, Loss: 0.000125\n",
      "Epoch: 15 Loss: 0.0\n",
      "Epoch: 17, Batch: 300, Loss: 0.000041\n",
      "Epoch: 17, Batch: 600, Loss: 0.000111\n",
      "Epoch: 17, Batch: 900, Loss: 0.000088\n",
      "Epoch: 16 Loss: 0.0\n",
      "Epoch: 18, Batch: 300, Loss: 0.000020\n",
      "Epoch: 18, Batch: 600, Loss: 0.000092\n",
      "Epoch: 18, Batch: 900, Loss: 0.000048\n",
      "Epoch: 17 Loss: 0.0\n",
      "Epoch: 19, Batch: 300, Loss: 0.000100\n",
      "Epoch: 19, Batch: 600, Loss: 0.000004\n",
      "Epoch: 19, Batch: 900, Loss: 0.000030\n",
      "Epoch: 18 Loss: 0.0\n",
      "Epoch: 20, Batch: 300, Loss: 0.000075\n",
      "Epoch: 20, Batch: 600, Loss: 0.000010\n",
      "Epoch: 20, Batch: 900, Loss: 0.000153\n",
      "Epoch: 19 Loss: 0.0\n",
      "Accuracy of the network on the 10000 test images: 99.18 %\n",
      "Epoch: 1, Batch: 300, Loss: 0.006320\n",
      "Epoch: 1, Batch: 600, Loss: 0.002794\n",
      "Epoch: 1, Batch: 900, Loss: 0.001084\n",
      "Epoch: 0 Loss: 0.0\n",
      "Epoch: 2, Batch: 300, Loss: 0.000583\n",
      "Epoch: 2, Batch: 600, Loss: 0.000355\n",
      "Epoch: 2, Batch: 900, Loss: 0.000096\n",
      "Epoch: 1 Loss: 0.0\n",
      "Epoch: 3, Batch: 300, Loss: 0.000623\n",
      "Epoch: 3, Batch: 600, Loss: 0.000199\n",
      "Epoch: 3, Batch: 900, Loss: 0.000046\n",
      "Epoch: 2 Loss: 0.0\n",
      "Epoch: 4, Batch: 300, Loss: 0.000073\n",
      "Epoch: 4, Batch: 600, Loss: 0.000183\n",
      "Epoch: 4, Batch: 900, Loss: 0.000179\n",
      "Epoch: 3 Loss: 0.0\n",
      "Epoch: 5, Batch: 300, Loss: 0.000134\n",
      "Epoch: 5, Batch: 600, Loss: 0.000228\n",
      "Epoch: 5, Batch: 900, Loss: 0.000076\n",
      "Epoch: 4 Loss: 0.0\n",
      "Epoch: 6, Batch: 300, Loss: 0.000094\n",
      "Epoch: 6, Batch: 600, Loss: 0.000212\n",
      "Epoch: 6, Batch: 900, Loss: 0.000257\n",
      "Epoch: 5 Loss: 0.0\n",
      "Epoch: 7, Batch: 300, Loss: 0.000086\n",
      "Epoch: 7, Batch: 600, Loss: 0.000040\n",
      "Epoch: 7, Batch: 900, Loss: 0.000149\n",
      "Epoch: 6 Loss: 0.0\n",
      "Epoch: 8, Batch: 300, Loss: 0.000179\n",
      "Epoch: 8, Batch: 600, Loss: 0.000321\n",
      "Epoch: 8, Batch: 900, Loss: 0.000050\n",
      "Epoch: 7 Loss: 0.0\n",
      "Epoch: 9, Batch: 300, Loss: 0.000159\n",
      "Epoch: 9, Batch: 600, Loss: 0.000374\n",
      "Epoch: 9, Batch: 900, Loss: 0.000271\n",
      "Epoch: 8 Loss: 0.0\n",
      "Epoch: 10, Batch: 300, Loss: 0.000111\n",
      "Epoch: 10, Batch: 600, Loss: 0.000153\n",
      "Epoch: 10, Batch: 900, Loss: 0.000318\n",
      "Epoch: 9 Loss: 0.0\n",
      "Epoch: 11, Batch: 300, Loss: 0.000020\n",
      "Epoch: 11, Batch: 600, Loss: 0.000021\n",
      "Epoch: 11, Batch: 900, Loss: 0.000170\n",
      "Epoch: 10 Loss: 0.0\n",
      "Epoch: 12, Batch: 300, Loss: 0.000080\n",
      "Epoch: 12, Batch: 600, Loss: 0.000080\n",
      "Epoch: 12, Batch: 900, Loss: 0.000029\n",
      "Epoch: 11 Loss: 0.0\n",
      "Epoch: 13, Batch: 300, Loss: 0.000076\n",
      "Epoch: 13, Batch: 600, Loss: 0.000193\n",
      "Epoch: 13, Batch: 900, Loss: 0.000125\n",
      "Epoch: 12 Loss: 0.0\n",
      "Epoch: 14, Batch: 300, Loss: 0.000009\n",
      "Epoch: 14, Batch: 600, Loss: 0.000088\n",
      "Epoch: 14, Batch: 900, Loss: 0.000008\n",
      "Epoch: 13 Loss: 0.0\n",
      "Epoch: 15, Batch: 300, Loss: 0.000025\n",
      "Epoch: 15, Batch: 600, Loss: 0.000004\n",
      "Epoch: 15, Batch: 900, Loss: 0.000028\n",
      "Epoch: 14 Loss: 0.0\n",
      "Epoch: 16, Batch: 300, Loss: 0.000152\n",
      "Epoch: 16, Batch: 600, Loss: 0.000262\n",
      "Epoch: 16, Batch: 900, Loss: 0.000004\n",
      "Epoch: 15 Loss: 0.0\n",
      "Epoch: 17, Batch: 300, Loss: 0.000156\n",
      "Epoch: 17, Batch: 600, Loss: 0.000217\n",
      "Epoch: 17, Batch: 900, Loss: 0.000020\n",
      "Epoch: 16 Loss: 0.0\n",
      "Epoch: 18, Batch: 300, Loss: 0.000026\n",
      "Epoch: 18, Batch: 600, Loss: 0.000157\n",
      "Epoch: 18, Batch: 900, Loss: 0.000132\n",
      "Epoch: 17 Loss: 0.0\n",
      "Epoch: 19, Batch: 300, Loss: 0.000069\n",
      "Epoch: 19, Batch: 600, Loss: 0.000079\n",
      "Epoch: 19, Batch: 900, Loss: 0.000018\n",
      "Epoch: 18 Loss: 0.0\n",
      "Epoch: 20, Batch: 300, Loss: 0.000006\n",
      "Epoch: 20, Batch: 600, Loss: 0.000011\n",
      "Epoch: 20, Batch: 900, Loss: 0.000106\n",
      "Epoch: 19 Loss: 0.0\n",
      "Accuracy of the network on the 10000 test images: 99.23 %\n",
      "Epoch: 1, Batch: 300, Loss: 0.006305\n",
      "Epoch: 1, Batch: 600, Loss: 0.001877\n",
      "Epoch: 1, Batch: 900, Loss: 0.000499\n",
      "Epoch: 0 Loss: 0.0\n",
      "Epoch: 2, Batch: 300, Loss: 0.000343\n",
      "Epoch: 2, Batch: 600, Loss: 0.001076\n",
      "Epoch: 2, Batch: 900, Loss: 0.000082\n",
      "Epoch: 1 Loss: 0.0\n",
      "Epoch: 3, Batch: 300, Loss: 0.000652\n",
      "Epoch: 3, Batch: 600, Loss: 0.000250\n",
      "Epoch: 3, Batch: 900, Loss: 0.000188\n",
      "Epoch: 2 Loss: 0.0\n",
      "Epoch: 4, Batch: 300, Loss: 0.000166\n",
      "Epoch: 4, Batch: 600, Loss: 0.000176\n",
      "Epoch: 4, Batch: 900, Loss: 0.000266\n",
      "Epoch: 3 Loss: 0.0\n",
      "Epoch: 5, Batch: 300, Loss: 0.000122\n",
      "Epoch: 5, Batch: 600, Loss: 0.000120\n",
      "Epoch: 5, Batch: 900, Loss: 0.000057\n",
      "Epoch: 4 Loss: 0.0\n",
      "Epoch: 6, Batch: 300, Loss: 0.000046\n",
      "Epoch: 6, Batch: 600, Loss: 0.000032\n",
      "Epoch: 6, Batch: 900, Loss: 0.000113\n",
      "Epoch: 5 Loss: 0.0\n",
      "Epoch: 7, Batch: 300, Loss: 0.000012\n",
      "Epoch: 7, Batch: 600, Loss: 0.000139\n",
      "Epoch: 7, Batch: 900, Loss: 0.000081\n",
      "Epoch: 6 Loss: 0.0\n",
      "Epoch: 8, Batch: 300, Loss: 0.000112\n",
      "Epoch: 8, Batch: 600, Loss: 0.000117\n",
      "Epoch: 8, Batch: 900, Loss: 0.000215\n",
      "Epoch: 7 Loss: 0.0\n",
      "Epoch: 9, Batch: 300, Loss: 0.000063\n",
      "Epoch: 9, Batch: 600, Loss: 0.000267\n",
      "Epoch: 9, Batch: 900, Loss: 0.000178\n",
      "Epoch: 8 Loss: 0.0\n",
      "Epoch: 10, Batch: 300, Loss: 0.000567\n",
      "Epoch: 10, Batch: 600, Loss: 0.000032\n",
      "Epoch: 10, Batch: 900, Loss: 0.000025\n",
      "Epoch: 9 Loss: 0.0\n",
      "Epoch: 11, Batch: 300, Loss: 0.000020\n",
      "Epoch: 11, Batch: 600, Loss: 0.000041\n",
      "Epoch: 11, Batch: 900, Loss: 0.000018\n",
      "Epoch: 10 Loss: 0.0\n",
      "Epoch: 12, Batch: 300, Loss: 0.000025\n",
      "Epoch: 12, Batch: 600, Loss: 0.000351\n",
      "Epoch: 12, Batch: 900, Loss: 0.000109\n",
      "Epoch: 11 Loss: 0.0\n",
      "Epoch: 13, Batch: 300, Loss: 0.000056\n",
      "Epoch: 13, Batch: 600, Loss: 0.000075\n",
      "Epoch: 13, Batch: 900, Loss: 0.000111\n",
      "Epoch: 12 Loss: 0.0\n",
      "Epoch: 14, Batch: 300, Loss: 0.000110\n",
      "Epoch: 14, Batch: 600, Loss: 0.000103\n",
      "Epoch: 14, Batch: 900, Loss: 0.000019\n",
      "Epoch: 13 Loss: 0.0\n",
      "Epoch: 15, Batch: 300, Loss: 0.000008\n",
      "Epoch: 15, Batch: 600, Loss: 0.000085\n",
      "Epoch: 15, Batch: 900, Loss: 0.000003\n",
      "Epoch: 14 Loss: 0.0\n",
      "Epoch: 16, Batch: 300, Loss: 0.000011\n",
      "Epoch: 16, Batch: 600, Loss: 0.000017\n",
      "Epoch: 16, Batch: 900, Loss: 0.000069\n",
      "Epoch: 15 Loss: 0.0\n",
      "Epoch: 17, Batch: 300, Loss: 0.000074\n",
      "Epoch: 17, Batch: 600, Loss: 0.000834\n",
      "Epoch: 17, Batch: 900, Loss: 0.000030\n",
      "Epoch: 16 Loss: 0.0\n",
      "Epoch: 18, Batch: 300, Loss: 0.000004\n",
      "Epoch: 18, Batch: 600, Loss: 0.000021\n",
      "Epoch: 18, Batch: 900, Loss: 0.000212\n",
      "Epoch: 17 Loss: 0.0\n",
      "Epoch: 19, Batch: 300, Loss: 0.000272\n",
      "Epoch: 19, Batch: 600, Loss: 0.000003\n",
      "Epoch: 19, Batch: 900, Loss: 0.000259\n",
      "Epoch: 18 Loss: 0.0\n",
      "Epoch: 20, Batch: 300, Loss: 0.000043\n",
      "Epoch: 20, Batch: 600, Loss: 0.000038\n",
      "Epoch: 20, Batch: 900, Loss: 0.000003\n",
      "Epoch: 19 Loss: 0.0\n",
      "Accuracy of the network on the 10000 test images: 99.29 %\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (5,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     test(model, test_loader)\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 17\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, acc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(accuracy_list):\n\u001b[1;32m     19\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtext(channels[i], acc, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, ha\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/matplotlib/pyplot.py:3829\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3821\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3828\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.10/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (5,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main():\n",
    "    device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epochs = 20\n",
    "    channels = [16, 32, 64, 128, 256]\n",
    "    accuracy_list = []\n",
    "\n",
    "    for channel in channels:\n",
    "        model = CAN(channel).to(device)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "        model = train(model, train_loader, optimizer, criterion, epochs, device)\n",
    "        accuracy = test(model, test_loader, device)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(channels, accuracy_list, marker=\"o\", label=\"Accuracy\")\n",
    "    for i, acc in enumerate(accuracy_list):\n",
    "        plt.text(channels[i], acc, f\"{acc:.2f}%\", fontsize=9, ha=\"center\")\n",
    "    plt.xlabel(\"Number of feature channels\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(\"Accuracy versus the number of channels\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"CAN_accuracy.png\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
